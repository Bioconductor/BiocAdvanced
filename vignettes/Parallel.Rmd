---
title: "Parallel evaluation"
author: "Martin Morgan"
date: "July 31 - August 1, 2018"
vignette: >
  %\VignetteIndexEntry{Parallel evaluation}
  %\VignetteEngine{knitr::rmarkdown}
output: 
  BiocStyle::html_document
---

```{r style, echo = FALSE, results = 'asis'}
knitr::opts_chunk$set(
    eval=as.logical(Sys.getenv("KNITR_EVAL", "TRUE")),
    cache=as.logical(Sys.getenv("KNITR_CACHE", "TRUE")))
```

Priorities

1. Correct
2. Robust
3. Clear
4. Efficient
5. Parallel

# Parallel evaluation

```{r}
fun <- function(i) {
    Sys.sleep(1)    # do a lot of computation
    i               # return a result
}
```

Question: What is the result of this expression? How long does it take to evaluate the following?

```{r}
res1 <- lapply(seq_len(5), fun)
```

Attach the [BiocParallel][] package, check out the arguments and help page for `bplapply()`

```{r}
library("BiocParallel")
args(bplapply)
```
```{r, eval = FALSE}
?bplapply
```

Look at the vignettes

```{r, eval = FALSE}
browseVignettes("BiocParallel")
```

Question: Does the following expression evaluate to the earlier `lapply()`? how long does it take to arrive at this result using `bplapply()`?

```{r}
res2 <- bplapply(seq_len(5), fun)
```

Use `parallel::detectCores()` to determine how many cores you have on your computer.

```{r}
ncores <- parallel::detectCores()
ncores
```

Each element in the `bplapply()` iteration is assigned to a core, and each core can only process one element at a time. Summarize the length of time it takes to run 1, 2, ... `ncores + 2` sequences on your computer

```{r}
vapply(seq_len(ncores + 2), function(n) {
    time <- system.time(bplapply(seq_len(n), fun))
    summary(time)[["elapsed"]]
}, numeric(1))
```

## Basic terminology

_manager_: the process from which `bplapply()` is called, usually an interactive _R_ session or _R_ script.

_worker_: a process started by `bplapply()`

_job_: the work to be done in a single call to `bplapply()`, i.e., the vector `X`.

_task_: The division of `X` into chunks for processing. If `X = seq_len(10)` and the number of tasks is equal to 5, then `X` is divided into 5 tasks `1:2`, `3:4`, `5:6`, `7:8`, `9:10`. and each task is sent to a worker for processing. 

The default number of tasks divides `X` as evenly as possible amongst workers; this is efficient when each task takes approximately the same amount of time. Setting the number of tasks (via one of the `*Param()` objects, below) to the length of `X` assigns one task to each worker in a round-robin fashion (the first worker to finish its task is given another to do). This is an easy way to perform 'load balancing', where one worker can process several short tasks while another struggles with a long task.

# Types of parallel workers

`SerialParam()`: there is only a single worker, identical to the manager; this is like `lapply()`

`MulticoreParam()`: (not available on Windows) workers are _forked_ processes on a single computer. A forked process shares memory with the manager process, so there is no need to, e.g., load packages on the worker or send data from the global environment to the worker.

`SnowParam()`: workers are _independent_ processes on one or several computers. Since the processes are separate, any data needed or generated by the worker needs to be sent to or from the manager. This is accomplished by serailizing _R_ objects to socket connections.

`BatchJobsParam()`: workers are _independent_ process on one or several computers. `BatchJobsParam()` is particularly suited to use on clusters where there is a job scheduler like SLURM, LSF, etc.

It's easy to switch between different scenarios

```{r}
res1 <- bplapply(seq_len(5), fun, BPPARAM = SerialParam())
res2 <- bplapply(seq_len(5), fun, BPPARAM = SnowParam())
```

# Errors

```{r}
fun <- function(i) {
    if (i == 3)
        stop("oops")
    i
}
res <- bptry(bplapply(seq_len(5), fun))
res
```

```{r}
fun1 <- function(i) {
    if (i == 3)
        i <- NA
    i
}
res1 <- bplapply(seq_len(5), fun1, BPREDO = res)
unlist(res1)
```

```{r, eval = FALSE}
options(error = recover)
bplapply(seq_len(5), fun, BPREDO = res, BPPARAM = SerialParam())
options(error = NULL)
```

# Iteration

## Iterating through genomic files

[GenomicFiles][] provides specialized functions for iterating through large genomic (e.g., VCF, BAM) files.

[BiocParallel]: https://bioconductor.org/packages/BiocParallel
[GenomicFiles]: https://bioconductor.org/packages/GenomicFiles
